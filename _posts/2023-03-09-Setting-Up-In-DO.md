* Wow, the [Arc Browser](https://thebrowser.company/) is amazing. I tried it several weeks ago and got distracted by other concerns and didn't use it for any amount of time. But yesterday I went back to it, read through the guides, and began moving some of my projects over to it. This is a game changer. (Such a cliche) Huge fan!
* Today was the end of Steward Tickets for Burning Man so I've been particularly busy herding all of the cats. Good stuff coming!
* Spent some time this morning speaking with a fellow entrepreneur about the accelerator and incubator ecosystem. This was a great talk and gave me some good insight into fine tuning my current efforts.
* This [update on Meta's carbon cost](https://kaspergroesludvigsen.medium.com/facebook-disclose-the-carbon-footprint-of-their-new-llama-models-9629a3c5c28b) for their new ML model is well received in my book.

> What’s really interesting about Facebook’s numbers is that they seem to account for all the GPU compute they used in the entire model development process – not just the compute from training the final version(s), which seems to otherwise be the norm.
